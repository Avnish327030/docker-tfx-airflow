[2022-03-24 15:50:56,033] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: census_consumer_complaint.Transform manual__2022-03-24T15:42:29.578379+00:00 [queued]>
[2022-03-24 15:50:56,040] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: census_consumer_complaint.Transform manual__2022-03-24T15:42:29.578379+00:00 [queued]>
[2022-03-24 15:50:56,040] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-03-24 15:50:56,040] {taskinstance.py:1244} INFO - Starting attempt 1 of 1
[2022-03-24 15:50:56,040] {taskinstance.py:1245} INFO - 
--------------------------------------------------------------------------------
[2022-03-24 15:50:56,049] {taskinstance.py:1264} INFO - Executing <Task(AirflowComponent): Transform> on 2022-03-24 15:42:29.578379+00:00
[2022-03-24 15:50:56,067] {standard_task_runner.py:52} INFO - Started process 757 to run task
[2022-03-24 15:50:56,071] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'census_consumer_complaint', 'Transform', 'manual__2022-03-24T15:42:29.578379+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/census_consumer_complaint.py', '--cfg-path', '/tmp/tmpdlanjgga', '--error-file', '/tmp/tmp3mafxo1j']
[2022-03-24 15:50:56,071] {standard_task_runner.py:77} INFO - Job 61: Subtask Transform
[2022-03-24 15:50:56,110] {logging_mixin.py:109} INFO - Running <TaskInstance: census_consumer_complaint.Transform manual__2022-03-24T15:42:29.578379+00:00 [running]> on host 691464fec4e5
[2022-03-24 15:50:56,151] {taskinstance.py:1431} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=census_consumer_complaint
AIRFLOW_CTX_TASK_ID=Transform
AIRFLOW_CTX_EXECUTION_DATE=2022-03-24T15:42:29.578379+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-03-24T15:42:29.578379+00:00
[2022-03-24 15:50:56,152] {base_component_launcher.py:190} INFO - Running driver for Transform
[2022-03-24 15:50:56,155] {metadata_store.py:101} INFO - MetadataStore with DB connection initialized
[2022-03-24 15:50:56,313] {base_component_launcher.py:196} INFO - Running executor for Transform
[2022-03-24 15:50:56,315] {executor_utils.py:128} INFO - Analyze the 'train' split and transform all splits when splits_config is not set.
[2022-03-24 15:50:56,316] {udf_utils.py:48} INFO - udf_utils.get_fn {'module_file': None, 'module_path': 'feature_engineering@/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'
[2022-03-24 15:50:56,316] {udf_utils.py:331} INFO - Installing '/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl' to a temporary directory.
[2022-03-24 15:50:56,316] {udf_utils.py:338} INFO - Executing: ['/usr/local/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpb49xcla7', '/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl']
[2022-03-24 15:51:01,001] {udf_utils.py:340} INFO - Successfully installed '/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl'.
[2022-03-24 15:51:01,002] {udf_utils.py:48} INFO - udf_utils.get_fn {'module_file': None, 'module_path': 'feature_engineering@/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'
[2022-03-24 15:51:01,003] {udf_utils.py:331} INFO - Installing '/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl' to a temporary directory.
[2022-03-24 15:51:01,003] {udf_utils.py:338} INFO - Executing: ['/usr/local/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpwait8fej', '/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl']
[2022-03-24 15:51:05,383] {udf_utils.py:340} INFO - Successfully installed '/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl'.
[2022-03-24 15:51:05,384] {udf_utils.py:331} INFO - Installing '/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl' to a temporary directory.
[2022-03-24 15:51:05,384] {udf_utils.py:338} INFO - Executing: ['/usr/local/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpmgyagozh', '/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl']
[2022-03-24 15:51:09,268] {udf_utils.py:340} INFO - Successfully installed '/opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/_wheels/tfx_user_code_Transform-0.0+a771a9c4e311edd1189745bf9146b2281be3b819e63daa8f4d2f6d881acc99c9-py3-none-any.whl'.
[2022-03-24 15:51:09,278] {tensor_representation_util.py:347} INFO - Feature Company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,279] {tensor_representation_util.py:353} INFO - Feature Company public response has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,279] {tensor_representation_util.py:347} INFO - Feature Company response to consumer has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,279] {tensor_representation_util.py:347} INFO - Feature Complaint ID has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,279] {tensor_representation_util.py:353} INFO - Feature Consumer complaint narrative has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,279] {tensor_representation_util.py:353} INFO - Feature Consumer consent provided? has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,279] {tensor_representation_util.py:347} INFO - Feature Consumer disputed? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,279] {tensor_representation_util.py:347} INFO - Feature Date received has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,280] {tensor_representation_util.py:347} INFO - Feature Date sent to company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,280] {tensor_representation_util.py:347} INFO - Feature Issue has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,280] {tensor_representation_util.py:347} INFO - Feature Product has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,280] {tensor_representation_util.py:353} INFO - Feature State has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,280] {tensor_representation_util.py:353} INFO - Feature Sub-issue has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,280] {tensor_representation_util.py:353} INFO - Feature Sub-product has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,280] {tensor_representation_util.py:347} INFO - Feature Submitted via has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,280] {tensor_representation_util.py:353} INFO - Feature Tags has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,280] {tensor_representation_util.py:347} INFO - Feature Timely response? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,280] {tensor_representation_util.py:353} INFO - Feature ZIP code has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,306] {logging_mixin.py:109} INFO - Columns: dict_keys(['Company', 'Company public response', 'Company response to consumer', 'Complaint ID', 'Consumer complaint narrative', 'Consumer consent provided?', 'Consumer disputed?', 'Date received', 'Date sent to company', 'Issue', 'Product', 'State', 'Sub-issue', 'Sub-product', 'Submitted via', 'Tags', 'Timely response?', 'ZIP code'])
[2022-03-24 15:51:09,306] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,306] {logging_mixin.py:109} INFO - Column: Tensor("inputs_16_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,307] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,327] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,330] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,330] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,336] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,337] {logging_mixin.py:109} INFO - Column: Tensor("inputs_4_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,337] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,343] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,346] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_1:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,346] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,353] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,353] {logging_mixin.py:109} INFO - Column: Tensor("inputs_15_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,353] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,360] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,362] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_2:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,389] {deprecation.py:347} WARNING - From /home/***/.local/lib/python3.7/site-packages/tensorflow_transform/tf_utils.py:289: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use ref() instead.
[2022-03-24 15:51:09,393] {tensor_representation_util.py:347} INFO - Feature Company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,393] {tensor_representation_util.py:353} INFO - Feature Company public response has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,393] {tensor_representation_util.py:347} INFO - Feature Company response to consumer has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,393] {tensor_representation_util.py:347} INFO - Feature Complaint ID has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,393] {tensor_representation_util.py:353} INFO - Feature Consumer complaint narrative has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,393] {tensor_representation_util.py:353} INFO - Feature Consumer consent provided? has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,393] {tensor_representation_util.py:347} INFO - Feature Consumer disputed? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,393] {tensor_representation_util.py:347} INFO - Feature Date received has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,393] {tensor_representation_util.py:347} INFO - Feature Date sent to company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,394] {tensor_representation_util.py:347} INFO - Feature Issue has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,394] {tensor_representation_util.py:347} INFO - Feature Product has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,394] {tensor_representation_util.py:353} INFO - Feature State has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,394] {tensor_representation_util.py:353} INFO - Feature Sub-issue has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,394] {tensor_representation_util.py:353} INFO - Feature Sub-product has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,394] {tensor_representation_util.py:347} INFO - Feature Submitted via has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,394] {tensor_representation_util.py:353} INFO - Feature Tags has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,394] {tensor_representation_util.py:347} INFO - Feature Timely response? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,394] {tensor_representation_util.py:353} INFO - Feature ZIP code has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,409] {logging_mixin.py:109} INFO - Columns: dict_keys(['Company', 'Company public response', 'Company response to consumer', 'Complaint ID', 'Consumer complaint narrative', 'Consumer consent provided?', 'Consumer disputed?', 'Date received', 'Date sent to company', 'Issue', 'Product', 'State', 'Sub-issue', 'Sub-product', 'Submitted via', 'Tags', 'Timely response?', 'ZIP code'])
[2022-03-24 15:51:09,409] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,409] {logging_mixin.py:109} INFO - Column: Tensor("inputs_16_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,410] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,416] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,418] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,418] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,424] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,424] {logging_mixin.py:109} INFO - Column: Tensor("inputs_4_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,425] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,432] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,434] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_1:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,435] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,441] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,441] {logging_mixin.py:109} INFO - Column: Tensor("inputs_15_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,441] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,447] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,449] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_2:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,481] {logging_mixin.py:109} INFO - Columns: dict_keys(['Company', 'Company public response', 'Company response to consumer', 'Complaint ID', 'Consumer complaint narrative', 'Consumer consent provided?', 'Consumer disputed?', 'Date received', 'Date sent to company', 'Issue', 'Product', 'State', 'Sub-issue', 'Sub-product', 'Submitted via', 'Tags', 'Timely response?', 'ZIP code'])
[2022-03-24 15:51:09,481] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,482] {logging_mixin.py:109} INFO - Column: Tensor("inputs_16_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,482] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,488] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,490] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,490] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,496] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,496] {logging_mixin.py:109} INFO - Column: Tensor("inputs_4_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,496] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,502] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,504] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_1:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,505] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,511] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,511] {logging_mixin.py:109} INFO - Column: Tensor("inputs_15_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,511] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,518] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,521] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_2:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,548] {tensor_representation_util.py:347} INFO - Feature Company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,548] {tensor_representation_util.py:353} INFO - Feature Company public response has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,548] {tensor_representation_util.py:347} INFO - Feature Company response to consumer has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,548] {tensor_representation_util.py:347} INFO - Feature Complaint ID has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,548] {tensor_representation_util.py:353} INFO - Feature Consumer complaint narrative has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,548] {tensor_representation_util.py:353} INFO - Feature Consumer consent provided? has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,548] {tensor_representation_util.py:347} INFO - Feature Consumer disputed? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,548] {tensor_representation_util.py:347} INFO - Feature Date received has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,549] {tensor_representation_util.py:347} INFO - Feature Date sent to company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,549] {tensor_representation_util.py:347} INFO - Feature Issue has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,549] {tensor_representation_util.py:347} INFO - Feature Product has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,549] {tensor_representation_util.py:353} INFO - Feature State has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,549] {tensor_representation_util.py:353} INFO - Feature Sub-issue has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,549] {tensor_representation_util.py:353} INFO - Feature Sub-product has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,549] {tensor_representation_util.py:347} INFO - Feature Submitted via has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,549] {tensor_representation_util.py:353} INFO - Feature Tags has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,549] {tensor_representation_util.py:347} INFO - Feature Timely response? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,549] {tensor_representation_util.py:353} INFO - Feature ZIP code has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:347} INFO - Feature Company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:353} INFO - Feature Company public response has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:347} INFO - Feature Company response to consumer has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:347} INFO - Feature Complaint ID has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:353} INFO - Feature Consumer complaint narrative has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:353} INFO - Feature Consumer consent provided? has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:347} INFO - Feature Consumer disputed? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:347} INFO - Feature Date received has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:347} INFO - Feature Date sent to company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:347} INFO - Feature Issue has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:347} INFO - Feature Product has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:353} INFO - Feature State has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:353} INFO - Feature Sub-issue has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:353} INFO - Feature Sub-product has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,550] {tensor_representation_util.py:347} INFO - Feature Submitted via has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,551] {tensor_representation_util.py:353} INFO - Feature Tags has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,551] {tensor_representation_util.py:347} INFO - Feature Timely response? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,551] {tensor_representation_util.py:353} INFO - Feature ZIP code has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:347} INFO - Feature Company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:353} INFO - Feature Company public response has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:347} INFO - Feature Company response to consumer has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:347} INFO - Feature Complaint ID has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:353} INFO - Feature Consumer complaint narrative has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:353} INFO - Feature Consumer consent provided? has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:347} INFO - Feature Consumer disputed? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:347} INFO - Feature Date received has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:347} INFO - Feature Date sent to company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:347} INFO - Feature Issue has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:347} INFO - Feature Product has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:353} INFO - Feature State has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:353} INFO - Feature Sub-issue has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:353} INFO - Feature Sub-product has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:347} INFO - Feature Submitted via has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,552] {tensor_representation_util.py:353} INFO - Feature Tags has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:347} INFO - Feature Timely response? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:353} INFO - Feature ZIP code has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:347} INFO - Feature Company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:353} INFO - Feature Company public response has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:347} INFO - Feature Company response to consumer has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:347} INFO - Feature Complaint ID has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:353} INFO - Feature Consumer complaint narrative has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:353} INFO - Feature Consumer consent provided? has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:347} INFO - Feature Consumer disputed? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:347} INFO - Feature Date received has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:347} INFO - Feature Date sent to company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:347} INFO - Feature Issue has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:347} INFO - Feature Product has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:353} INFO - Feature State has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:353} INFO - Feature Sub-issue has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,553] {tensor_representation_util.py:353} INFO - Feature Sub-product has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,554] {tensor_representation_util.py:347} INFO - Feature Submitted via has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,554] {tensor_representation_util.py:353} INFO - Feature Tags has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,554] {tensor_representation_util.py:347} INFO - Feature Timely response? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:09,554] {tensor_representation_util.py:353} INFO - Feature ZIP code has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:09,555] {pipeline.py:188} INFO - Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.
[2022-03-24 15:51:09,563] {decorators.py:371} WARNING - This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.
[2022-03-24 15:51:09,598] {logging_mixin.py:109} INFO - Columns: dict_keys(['Company', 'Company public response', 'Company response to consumer', 'Complaint ID', 'Consumer complaint narrative', 'Consumer consent provided?', 'Consumer disputed?', 'Date received', 'Date sent to company', 'Issue', 'Product', 'State', 'Sub-issue', 'Sub-product', 'Submitted via', 'Tags', 'Timely response?', 'ZIP code'])
[2022-03-24 15:51:09,598] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,598] {logging_mixin.py:109} INFO - Column: Tensor("inputs_16_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,599] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,605] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,607] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,607] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,613] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,613] {logging_mixin.py:109} INFO - Column: Tensor("inputs_4_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,614] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,623] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,625] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_1:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,625] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,631] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,631] {logging_mixin.py:109} INFO - Column: Tensor("inputs_15_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,632] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,638] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,640] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_2:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,655] {graph_tools.py:597} WARNING - Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2
[2022-03-24 15:51:09,656] {graph_tools.py:597} WARNING - Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2
[2022-03-24 15:51:09,656] {graph_tools.py:597} WARNING - Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2
[2022-03-24 15:51:09,656] {graph_tools.py:597} WARNING - Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2
[2022-03-24 15:51:09,656] {graph_tools.py:597} WARNING - Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2
[2022-03-24 15:51:09,678] {logging_mixin.py:109} INFO - Columns: dict_keys(['Company', 'Company public response', 'Company response to consumer', 'Complaint ID', 'Consumer complaint narrative', 'Consumer consent provided?', 'Consumer disputed?', 'Date received', 'Date sent to company', 'Issue', 'Product', 'State', 'Sub-issue', 'Sub-product', 'Submitted via', 'Tags', 'Timely response?', 'ZIP code'])
[2022-03-24 15:51:09,678] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,678] {logging_mixin.py:109} INFO - Column: Tensor("inputs_16_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,679] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,685] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,687] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,687] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,693] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,693] {logging_mixin.py:109} INFO - Column: Tensor("inputs_4_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,693] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,699] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,701] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_1:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,702] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,707] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,707] {logging_mixin.py:109} INFO - Column: Tensor("inputs_15_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,708] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,714] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,716] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_2:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,731] {graph_tools.py:597} WARNING - Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2
[2022-03-24 15:51:09,731] {graph_tools.py:597} WARNING - Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2
[2022-03-24 15:51:09,731] {graph_tools.py:597} WARNING - Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2
[2022-03-24 15:51:09,732] {graph_tools.py:597} WARNING - Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2
[2022-03-24 15:51:09,732] {graph_tools.py:597} WARNING - Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2
[2022-03-24 15:51:09,741] {decorators.py:371} WARNING - This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.
[2022-03-24 15:51:09,836] {logging_mixin.py:109} INFO - Columns: dict_keys(['Company', 'Company public response', 'Company response to consumer', 'Complaint ID', 'Consumer complaint narrative', 'Consumer consent provided?', 'Consumer disputed?', 'Date received', 'Date sent to company', 'Issue', 'Product', 'State', 'Sub-issue', 'Sub-product', 'Submitted via', 'Tags', 'Timely response?', 'ZIP code'])
[2022-03-24 15:51:09,836] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,836] {logging_mixin.py:109} INFO - Column: Tensor("inputs_16_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,837] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,845] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,847] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,848] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,857] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,857] {logging_mixin.py:109} INFO - Column: Tensor("inputs_4_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,857] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,864] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,866] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_1:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:09,867] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,873] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:09,873] {logging_mixin.py:109} INFO - Column: Tensor("inputs_15_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:09,874] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:09,880] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:09,883] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_2:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:11,228] {logging_mixin.py:109} INFO - Columns: dict_keys(['Company', 'Company public response', 'Company response to consumer', 'Complaint ID', 'Consumer complaint narrative', 'Consumer consent provided?', 'Consumer disputed?', 'Date received', 'Date sent to company', 'Issue', 'Product', 'State', 'Sub-issue', 'Sub-product', 'Submitted via', 'Tags', 'Timely response?', 'ZIP code'])
[2022-03-24 15:51:11,229] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:11,229] {logging_mixin.py:109} INFO - Column: Tensor("PlaceholderWithDefault_16:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:11,229] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:11,237] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:11,240] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:11,240] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:11,248] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:11,248] {logging_mixin.py:109} INFO - Column: Tensor("PlaceholderWithDefault_4:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:11,248] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:11,256] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:11,258] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_1:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:11,259] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:11,266] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:11,266] {logging_mixin.py:109} INFO - Column: Tensor("PlaceholderWithDefault_15:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:11,267] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:11,274] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:11,276] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_2:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:11,740] {native_type_compatibility.py:248} INFO - Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]
[2022-03-24 15:51:11,741] {native_type_compatibility.py:248} INFO - Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]
[2022-03-24 15:51:11,742] {native_type_compatibility.py:248} INFO - Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]
[2022-03-24 15:51:12,033] {tensor_representation_util.py:347} INFO - Feature Company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,033] {tensor_representation_util.py:353} INFO - Feature Company public response has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,033] {tensor_representation_util.py:347} INFO - Feature Company response to consumer has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,033] {tensor_representation_util.py:347} INFO - Feature Complaint ID has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:353} INFO - Feature Consumer complaint narrative has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:353} INFO - Feature Consumer consent provided? has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:347} INFO - Feature Consumer disputed? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:347} INFO - Feature Date received has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:347} INFO - Feature Date sent to company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:347} INFO - Feature Issue has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:347} INFO - Feature Product has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:353} INFO - Feature State has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:353} INFO - Feature Sub-issue has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:353} INFO - Feature Sub-product has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:347} INFO - Feature Submitted via has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:353} INFO - Feature Tags has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:347} INFO - Feature Timely response? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,034] {tensor_representation_util.py:353} INFO - Feature ZIP code has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,111] {tensor_representation_util.py:347} INFO - Feature Company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,111] {tensor_representation_util.py:353} INFO - Feature Company public response has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,111] {tensor_representation_util.py:347} INFO - Feature Company response to consumer has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:347} INFO - Feature Complaint ID has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:353} INFO - Feature Consumer complaint narrative has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:353} INFO - Feature Consumer consent provided? has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:347} INFO - Feature Consumer disputed? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:347} INFO - Feature Date received has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:347} INFO - Feature Date sent to company has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:347} INFO - Feature Issue has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:347} INFO - Feature Product has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:353} INFO - Feature State has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:353} INFO - Feature Sub-issue has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:353} INFO - Feature Sub-product has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:347} INFO - Feature Submitted via has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:353} INFO - Feature Tags has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:347} INFO - Feature Timely response? has a shape dim {
  size: 1
}
. Setting to DenseTensor.
[2022-03-24 15:51:12,112] {tensor_representation_util.py:353} INFO - Feature ZIP code has no shape. Setting to VarLenSparseTensor.
[2022-03-24 15:51:12,284] {native_type_compatibility.py:248} INFO - Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]
[2022-03-24 15:51:12,285] {native_type_compatibility.py:248} INFO - Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]
[2022-03-24 15:51:12,286] {native_type_compatibility.py:248} INFO - Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.types.FeaturePath, ForwardRef('schema_pb2.FeatureType')]
[2022-03-24 15:51:12,954] {environments.py:374} WARNING - Make sure that locally built Python SDK docker image has Python 3.7 interpreter.
[2022-03-24 15:51:12,954] {environments.py:380} INFO - Default Python SDK image for environment is apache/beam_python3.7_sdk:2.37.0
[2022-03-24 15:51:15,136] {translations.py:678} INFO - ==================== <function annotate_downstream_side_inputs at 0x7f28364cd950> ====================
[2022-03-24 15:51:15,144] {translations.py:678} INFO - ==================== <function fix_side_input_pcoll_coders at 0x7f28364cda70> ====================
[2022-03-24 15:51:15,149] {translations.py:678} INFO - ==================== <function pack_combiners at 0x7f28364cdf80> ====================
[2022-03-24 15:51:15,162] {translations.py:678} INFO - ==================== <function lift_combiners at 0x7f28364ce050> ====================
[2022-03-24 15:51:15,211] {translations.py:678} INFO - ==================== <function expand_sdf at 0x7f28364ce200> ====================
[2022-03-24 15:51:15,224] {translations.py:678} INFO - ==================== <function expand_gbk at 0x7f28364ce290> ====================
[2022-03-24 15:51:15,235] {translations.py:678} INFO - ==================== <function sink_flattens at 0x7f28364ce3b0> ====================
[2022-03-24 15:51:15,240] {translations.py:678} INFO - ==================== <function greedily_fuse at 0x7f28364ce440> ====================
[2022-03-24 15:51:15,274] {translations.py:678} INFO - ==================== <function read_to_impulse at 0x7f28364ce4d0> ====================
[2022-03-24 15:51:15,276] {translations.py:678} INFO - ==================== <function impulse_to_input at 0x7f28364ce560> ====================
[2022-03-24 15:51:15,278] {translations.py:678} INFO - ==================== <function sort_stages at 0x7f28364ce7a0> ====================
[2022-03-24 15:51:15,286] {translations.py:678} INFO - ==================== <function setup_timer_mapping at 0x7f28364ce710> ====================
[2022-03-24 15:51:15,289] {translations.py:678} INFO - ==================== <function populate_data_channel_coders at 0x7f28364ce830> ====================
[2022-03-24 15:51:15,530] {statecache.py:172} INFO - Creating state cache with size 100
[2022-03-24 15:51:15,531] {worker_handlers.py:894} INFO - Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f28b3ce6610> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')
[2022-03-24 15:51:15,531] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_3-vocabulary-ApplyThresho_396)+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_3-vocabulary-ApplyThresho_397))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_3-vocabulary-ApplyThresho_399))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_3#vocabulary]/ApplyThresholdsAndTopK/Top(61)/Flatten/Transcode/1))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_3#vocabulary]/ApplyThresholdsAndTopK/Top(61)/Flatten/Write/1)
[2022-03-24 15:51:15,549] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_Analyze-CreateSavedModelForAnalyzerInputs-Phase0-tf_v2_only-CreateSole-Impulse_44)+(ref_AppliedPTransform_Analyze-CreateSavedModelForAnalyzerInputs-Phase0-tf_v2_only-CreateSole-FlatMap_45))+(ref_AppliedPTransform_Analyze-CreateSavedModelForAnalyzerInputs-Phase0-tf_v2_only-CreateSole-Map-dec_47))+(ref_AppliedPTransform_Analyze-CreateSavedModelForAnalyzerInputs-Phase0-tf_v2_only-CreateSavedModel_48))+(ref_PCollection_PCollection_23/Write)
[2022-03-24 15:51:15,583] {logging_mixin.py:109} INFO - Columns: dict_keys(['Company', 'Company public response', 'Company response to consumer', 'Complaint ID', 'Consumer complaint narrative', 'Consumer consent provided?', 'Consumer disputed?', 'Date received', 'Date sent to company', 'Issue', 'Product', 'State', 'Sub-issue', 'Sub-product', 'Submitted via', 'Tags', 'Timely response?', 'ZIP code'])
[2022-03-24 15:51:15,584] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:15,584] {logging_mixin.py:109} INFO - Column: Tensor("inputs_16_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:15,584] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:15,591] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:15,593] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:15,593] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:15,600] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:15,600] {logging_mixin.py:109} INFO - Column: Tensor("inputs_4_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:15,600] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:15,607] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:15,609] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_1:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:15,609] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:15,616] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:51:15,616] {logging_mixin.py:109} INFO - Column: Tensor("inputs_15_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:51:15,617] {analyzers.py:1858} INFO - If the number of unique tokens is smaller than the provided top_k or approximation error is acceptable, consider using tft.experimental.approximate_vocabulary for a potentially more efficient implementation.
[2022-03-24 15:51:15,624] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:51:15,626] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_2:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:51:15,918] {builder_impl.py:784} INFO - Assets written to: /opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/Transform/transform_graph/10/.temp_path/tftransform_tmp/4c1680dcbc9b41ed83eb5e99b974716e/assets
[2022-03-24 15:51:15,946] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_TFXIOReadAndDecode-AnalysisIndex0-RawRecordBeamSource-ReadRawRecords-ReadFromT_20)+(ref_AppliedPTransform_TFXIOReadAndDecode-AnalysisIndex0-RawRecordBeamSource-ReadRawRecords-ReadFromT_21))+(TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/PairWithRestriction))+(TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/SplitAndSizeRestriction))+(ref_PCollection_PCollection_9_split/Write)
[2022-03-24 15:51:15,982] {fn_runner.py:621} INFO - Running (((((((((((((((((((((((((((((((((((((((((((((((((((((((ref_PCollection_PCollection_9_split/Read)+(TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process))+(ref_AppliedPTransform_TFXIOReadAndDecode-AnalysisIndex0-RawRecordBeamSource-ReadRawRecords-FlattenPC_24))+(ref_AppliedPTransform_TFXIOReadAndDecode-AnalysisIndex0-RawRecordBeamSource-CollectRawRecordTelemetr_26))+(ref_AppliedPTransform_TFXIOReadAndDecode-AnalysisIndex0-RawRecordToRecordBatch-RawRecordToRecordBatc_30))+(ref_AppliedPTransform_TFXIOReadAndDecode-AnalysisIndex0-RawRecordToRecordBatch-RawRecordToRecordBatc_31))+(ref_AppliedPTransform_TFXIOReadAndDecode-AnalysisIndex0-RawRecordToRecordBatch-CollectRecordBatchTel_33))+(ref_AppliedPTransform_Analyze-ExtractInputForSavedModel-AnalysisIndex0-Identity_57))+(ref_AppliedPTransform_FlattenAnalysisDatasets_712))+(ref_AppliedPTransform_Analyze-ApplySavedModel-Phase0-AnalysisIndex0-ApplySavedModel_59))+(ref_AppliedPTransform_Analyze-ApplySavedModel-Phase0-AnalysisIndex0-ConvertToNumpy_60))+(ref_AppliedPTransform_Analyze-TensorSource-compute_and_apply_vocabulary-vocabulary-AnalysisIndex0-Ex_62))+(ref_AppliedPTransform_Analyze-TensorSource-compute_and_apply_vocabulary_1-vocabulary-AnalysisIndex0-_159))+(ref_AppliedPTransform_Analyze-TensorSource-compute_and_apply_vocabulary_2-vocabulary-AnalysisIndex0-_256))+(ref_AppliedPTransform_Analyze-TensorSource-compute_and_apply_vocabulary_3-vocabulary-AnalysisIndex0-_353))+(ref_AppliedPTransform_Analyze-TensorSource-compute_and_apply_vocabulary_4-vocabulary-AnalysisIndex0-_450))+(ref_AppliedPTransform_Analyze-VocabularyAccumulate-compute_and_apply_vocabulary-vocabulary-AnalysisI_64))+(ref_AppliedPTransform_Analyze-VocabularyAccumulate-compute_and_apply_vocabulary-vocabulary-AnalysisI_66))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Precombine))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyAccumulate-compute_and_apply_vocabulary_1-vocabulary-Analysi_161))+(ref_AppliedPTransform_Analyze-VocabularyAccumulate-compute_and_apply_vocabulary_1-vocabulary-Analysi_163))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_1#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Precombine))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_1#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyAccumulate-compute_and_apply_vocabulary_2-vocabulary-Analysi_258))+(ref_AppliedPTransform_Analyze-VocabularyAccumulate-compute_and_apply_vocabulary_2-vocabulary-Analysi_260))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_2#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Precombine))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_2#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyAccumulate-compute_and_apply_vocabulary_3-vocabulary-Analysi_355))+(ref_AppliedPTransform_Analyze-VocabularyAccumulate-compute_and_apply_vocabulary_3-vocabulary-Analysi_357))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_3#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Precombine))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_3#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyAccumulate-compute_and_apply_vocabulary_4-vocabulary-Analysi_452))+(ref_AppliedPTransform_Analyze-VocabularyAccumulate-compute_and_apply_vocabulary_4-vocabulary-Analysi_454))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_4#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Precombine))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_4#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Group/Write))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-FilterInternalColumn_714))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_718))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-K_733))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_720))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackTotalBytes/SumTotalBytes/CombinePerKey/Precombine))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackTotalBytes/SumTotalBytes/CombinePerKey/Group/Write))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_736))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_762))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_789))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_738))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/RemoveDuplicates/Group/Precombine))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/RemoveDuplicates/Group/Group/Write))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_764))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/CombineCountsAndWeights/CombinePerKey(sum)/Precombine))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/CombineCountsAndWeights/CombinePerKey(sum)/Group/Write))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_790))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/Flatten/Transcode/0))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PreCombineFn)/Precombine))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PreCombineFn)/Group/Write))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/Flatten/Write/0)
[2022-03-24 15:51:16,354] {tfrecordio.py:60} WARNING - Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.
[2022-03-24 15:51:16,465] {saved_transform_io.py:166} INFO - tensorflow_text is not available.
[2022-03-24 15:51:16,466] {saved_transform_io.py:166} INFO - tensorflow_decision_forests is not available.
[2022-03-24 15:51:16,466] {saved_transform_io.py:166} INFO - struct2tensor is not available.
[2022-03-24 15:52:37,135] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex3-Write-WriteImpl-DoOnce-Impulse_684)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex3-Write-WriteImpl-DoOnce-FlatMap-_685))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex3-Write-WriteImpl-DoOnce-Map-deco_687))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex3-Write-WriteImpl-InitializeWrite_688))+(ref_PCollection_PCollection_396/Write))+(ref_PCollection_PCollection_397/Write)
[2022-03-24 15:52:37,157] {fn_runner.py:621} INFO - Running (((((((((((Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_3#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Group/Read)+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_3#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Merge))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_3#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/ExtractOutputs))+(Analyze/FlattenCache[VocabularyMerge[compute_and_apply_vocabulary_3#vocabulary]]/Flatten/Transcode/0))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_3-vocabu_589))+(ref_AppliedPTransform_Analyze-FlattenCache-VocabularyMerge-compute_and_apply_vocabulary_3-vocabulary_363))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_3#vocabulary]/MergeCountPerToken/Precombine))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_3#vocabulary]/MergeCountPerToken/Group/Write))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex3-Write-WriteImpl-WindowInto-Wind_689))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex3-Write-WriteImpl-WriteBundles_690))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex3-Write-WriteImpl-Pair_691))+(WriteCache/Write[AnalysisIndex0][CacheKeyIndex3]/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:37,189] {fn_runner.py:621} INFO - Running (((((((((((Analyze/VocabularyMerge[compute_and_apply_vocabulary_3#vocabulary]/MergeCountPerToken/Group/Read)+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_3#vocabulary]/MergeCountPerToken/Merge))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_3#vocabulary]/MergeCountPerToken/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyMerge-compute_and_apply_vocabulary_3-vocabulary-SwapTokensAn_370))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_3-vocabulary-To_374))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_3-vocabulary-KeepOnlyVali_390))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_3#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_3#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_3-vocabulary-ApplyThresho_392))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_3-vocabulary-ApplyThresho_394))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_3#vocabulary]/ApplyThresholdsAndTopK/Top(61)/Flatten/Transcode/0))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_3#vocabulary]/ApplyThresholdsAndTopK/Top(61)/Flatten/Write/0)
[2022-03-24 15:52:37,216] {fn_runner.py:621} INFO - Running (Analyze/VocabularyPrune[compute_and_apply_vocabulary_3#vocabulary]/ApplyThresholdsAndTopK/Top(61)/Flatten/Read)+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_3#vocabulary]/ApplyThresholdsAndTopK/Top(61)/GroupByKey/Write)
[2022-03-24 15:52:37,226] {fn_runner.py:621} INFO - Running ((((((((((Analyze/VocabularyPrune[compute_and_apply_vocabulary_3#vocabulary]/ApplyThresholdsAndTopK/Top(61)/GroupByKey/Read)+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_3-vocabulary-ApplyThresho_402))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_3-vocabulary-ApplyThresho_403))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_3-vocabulary-ApplyThresho_404))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_3-vocabulary-Tota_408))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Extr_425))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_3#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_3#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Writ_435))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Writ_436))+(Analyze/VocabularyOrderAndWrite[compute_and_apply_vocabulary_3#vocabulary]/WriteToText/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:37,259] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Writ_430)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Writ_431))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Writ_433))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Writ_434))+(ref_PCollection_PCollection_242/Write))+(ref_PCollection_PCollection_243/Write)
[2022-03-24 15:52:37,278] {fn_runner.py:621} INFO - Running ((Analyze/VocabularyOrderAndWrite[compute_and_apply_vocabulary_3#vocabulary]/WriteToText/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Writ_438))+(ref_PCollection_PCollection_247/Write)
[2022-03-24 15:52:37,297] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex2-Write-WriteImpl-DoOnce-Impulse_668)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex2-Write-WriteImpl-DoOnce-FlatMap-_669))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex2-Write-WriteImpl-DoOnce-Map-deco_671))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex2-Write-WriteImpl-InitializeWrite_672))+(ref_PCollection_PCollection_385/Write))+(ref_PCollection_PCollection_386/Write)
[2022-03-24 15:52:37,317] {fn_runner.py:621} INFO - Running (((((((((((Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_2#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Group/Read)+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_2#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Merge))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_2#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/ExtractOutputs))+(Analyze/FlattenCache[VocabularyMerge[compute_and_apply_vocabulary_2#vocabulary]]/Flatten/Transcode/0))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_2-vocabu_580))+(ref_AppliedPTransform_Analyze-FlattenCache-VocabularyMerge-compute_and_apply_vocabulary_2-vocabulary_266))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_2#vocabulary]/MergeCountPerToken/Precombine))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_2#vocabulary]/MergeCountPerToken/Group/Write))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex2-Write-WriteImpl-WindowInto-Wind_673))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex2-Write-WriteImpl-WriteBundles_674))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex2-Write-WriteImpl-Pair_675))+(WriteCache/Write[AnalysisIndex0][CacheKeyIndex2]/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:37,344] {fn_runner.py:621} INFO - Running (((((((((((Analyze/VocabularyMerge[compute_and_apply_vocabulary_2#vocabulary]/MergeCountPerToken/Group/Read)+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_2#vocabulary]/MergeCountPerToken/Merge))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_2#vocabulary]/MergeCountPerToken/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyMerge-compute_and_apply_vocabulary_2-vocabulary-SwapTokensAn_273))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_2-vocabulary-To_277))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_2-vocabulary-KeepOnlyVali_293))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_2#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_2#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_2-vocabulary-ApplyThresho_295))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_2-vocabulary-ApplyThresho_297))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_2#vocabulary]/ApplyThresholdsAndTopK/Top(6)/Flatten/Transcode/0))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_2#vocabulary]/ApplyThresholdsAndTopK/Top(6)/Flatten/Write/0)
[2022-03-24 15:52:37,370] {fn_runner.py:621} INFO - Running ((((Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_2#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_2#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_2#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_2-vocabulary-To_282))+(ref_PCollection_PCollection_155/Write)
[2022-03-24 15:52:37,388] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_2-vocabulary-ApplyThresho_299)+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_2-vocabulary-ApplyThresho_300))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_2-vocabulary-ApplyThresho_302))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_2#vocabulary]/ApplyThresholdsAndTopK/Top(6)/Flatten/Transcode/1))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_2#vocabulary]/ApplyThresholdsAndTopK/Top(6)/Flatten/Write/1)
[2022-03-24 15:52:37,407] {fn_runner.py:621} INFO - Running (Analyze/VocabularyPrune[compute_and_apply_vocabulary_2#vocabulary]/ApplyThresholdsAndTopK/Top(6)/Flatten/Read)+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_2#vocabulary]/ApplyThresholdsAndTopK/Top(6)/GroupByKey/Write)
[2022-03-24 15:52:37,451] {fn_runner.py:621} INFO - Running ((((((((((Analyze/VocabularyPrune[compute_and_apply_vocabulary_2#vocabulary]/ApplyThresholdsAndTopK/Top(6)/GroupByKey/Read)+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_2-vocabulary-ApplyThresho_305))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_2-vocabulary-ApplyThresho_306))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_2-vocabulary-ApplyThresho_307))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_2-vocabulary-Tota_311))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Extr_328))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_2#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_2#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Writ_338))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Writ_339))+(Analyze/VocabularyOrderAndWrite[compute_and_apply_vocabulary_2#vocabulary]/WriteToText/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:37,487] {fn_runner.py:621} INFO - Running ((((Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_2#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_2#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_2#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_2-vocabulary-Tota_316))+(ref_PCollection_PCollection_176/Write)
[2022-03-24 15:52:37,502] {fn_runner.py:621} INFO - Running ((((((ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_2-vocabulary-Tota_318)+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_2-vocabulary-Tota_319))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_2-vocabulary-Tota_321))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_2-vocabulary-Tota_322))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_2-vocabulary-ToIn_323))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_2-vocabulary-temporar_325))+(ref_PCollection_PCollection_182/Write)
[2022-03-24 15:52:37,528] {fn_runner.py:621} INFO - Running ((((((ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_2-vocabulary-To_284)+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_2-vocabulary-To_285))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_2-vocabulary-To_287))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_2-vocabulary-To_288))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_2-vocabulary-To_289))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_2-vocabulary-temporar_291))+(ref_PCollection_PCollection_161/Write)
[2022-03-24 15:52:37,559] {fn_runner.py:621} INFO - Running ((((Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_3#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_3#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_3#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_3-vocabulary-Tota_413))+(ref_PCollection_PCollection_232/Write)
[2022-03-24 15:52:37,574] {fn_runner.py:621} INFO - Running ((((((ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_3-vocabulary-Tota_415)+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_3-vocabulary-Tota_416))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_3-vocabulary-Tota_418))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_3-vocabulary-Tota_419))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_3-vocabulary-ToIn_420))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_3-vocabulary-temporar_422))+(ref_PCollection_PCollection_238/Write)
[2022-03-24 15:52:37,600] {fn_runner.py:621} INFO - Running ((((((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PreCombineFn)/Group/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PreCombineFn)/Merge))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PreCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_795))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_796))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/Flatten/Transcode/1))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/Flatten/Write/1)
[2022-03-24 15:52:37,630] {fn_runner.py:621} INFO - Running ((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/Flatten/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PostCombineFn)/Precombine))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PostCombineFn)/Group/Write)
[2022-03-24 15:52:37,647] {fn_runner.py:621} INFO - Running ((((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PostCombineFn)/Group/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PostCombineFn)/Merge))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PostCombineFn)/ExtractOutputs))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Transcode/1))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Write/1)
[2022-03-24 15:52:37,674] {fn_runner.py:621} INFO - Running (((((((((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/CombineCountsAndWeights/CombinePerKey(sum)/Group/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/CombineCountsAndWeights/CombinePerKey(sum)/Merge))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/CombineCountsAndWeights/CombinePerKey(sum)/ExtractOutputs))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_769))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Unweighted_TopK/CombinePerKey(TopCombineFn)/Precombine))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_778))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Unweighted_TopK/CombinePerKey(TopCombineFn)/Group/Write))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_780))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Precombine))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Group/Write)
[2022-03-24 15:52:39,208] {fn_runner.py:621} INFO - Running (((((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Unweighted_TopK/CombinePerKey(TopCombineFn)/Group/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Unweighted_TopK/CombinePerKey(TopCombineFn)/Merge))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Unweighted_TopK/CombinePerKey(TopCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_775))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_776))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesFeatureStatsProtos/Write/0)
[2022-03-24 15:52:39,249] {fn_runner.py:621} INFO - Running ((((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Group/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Merge))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_785))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesFeatureStatsProtos/Write/1)
[2022-03-24 15:52:39,265] {fn_runner.py:621} INFO - Running ((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesFeatureStatsProtos/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Transcode/0))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Write/0)
[2022-03-24 15:52:39,282] {fn_runner.py:621} INFO - Running ((((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Read)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_803))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_806))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Precombine))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Group/Write)
[2022-03-24 15:52:39,308] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Materialize-TransformIndex1-Write-Write-WriteImpl-DoOnce-Impulse_1109)+(ref_AppliedPTransform_Materialize-TransformIndex1-Write-Write-WriteImpl-DoOnce-FlatMap-lambda-at-cor_1110))+(ref_AppliedPTransform_Materialize-TransformIndex1-Write-Write-WriteImpl-DoOnce-Map-decode-_1112))+(ref_AppliedPTransform_Materialize-TransformIndex1-Write-Write-WriteImpl-InitializeWrite_1113))+(ref_PCollection_PCollection_653/Write))+(ref_PCollection_PCollection_654/Write)
[2022-03-24 15:52:39,331] {fn_runner.py:621} INFO - Running ((((Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_3#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_3#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_3#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_3-vocabulary-To_379))+(ref_PCollection_PCollection_211/Write)
[2022-03-24 15:52:39,348] {fn_runner.py:621} INFO - Running ((((((ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_3-vocabulary-To_381)+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_3-vocabulary-To_382))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_3-vocabulary-To_384))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_3-vocabulary-To_385))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_3-vocabulary-To_386))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_3-vocabulary-temporar_388))+(ref_PCollection_PCollection_217/Write)
[2022-03-24 15:52:39,377] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_1-vocabulary-ApplyThresho_202)+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_1-vocabulary-ApplyThresho_203))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_1-vocabulary-ApplyThresho_205))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_1#vocabulary]/ApplyThresholdsAndTopK/Top(46)/Flatten/Transcode/1))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_1#vocabulary]/ApplyThresholdsAndTopK/Top(46)/Flatten/Write/1)
[2022-03-24 15:52:39,396] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex1-Write-WriteImpl-DoOnce-Impulse_652)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex1-Write-WriteImpl-DoOnce-FlatMap-_653))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex1-Write-WriteImpl-DoOnce-Map-deco_655))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex1-Write-WriteImpl-InitializeWrite_656))+(ref_PCollection_PCollection_374/Write))+(ref_PCollection_PCollection_375/Write)
[2022-03-24 15:52:39,418] {fn_runner.py:621} INFO - Running (((((((((((Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_1#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Group/Read)+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_1#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Merge))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_1#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/ExtractOutputs))+(Analyze/FlattenCache[VocabularyMerge[compute_and_apply_vocabulary_1#vocabulary]]/Flatten/Transcode/0))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_1-vocabu_571))+(ref_AppliedPTransform_Analyze-FlattenCache-VocabularyMerge-compute_and_apply_vocabulary_1-vocabulary_169))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_1#vocabulary]/MergeCountPerToken/Precombine))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_1#vocabulary]/MergeCountPerToken/Group/Write))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex1-Write-WriteImpl-WindowInto-Wind_657))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex1-Write-WriteImpl-WriteBundles_658))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex1-Write-WriteImpl-Pair_659))+(WriteCache/Write[AnalysisIndex0][CacheKeyIndex1]/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:39,451] {fn_runner.py:621} INFO - Running (((((((((((Analyze/VocabularyMerge[compute_and_apply_vocabulary_1#vocabulary]/MergeCountPerToken/Group/Read)+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_1#vocabulary]/MergeCountPerToken/Merge))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_1#vocabulary]/MergeCountPerToken/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyMerge-compute_and_apply_vocabulary_1-vocabulary-SwapTokensAn_176))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_1-vocabulary-To_180))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_1-vocabulary-KeepOnlyVali_196))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_1#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_1#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_1-vocabulary-ApplyThresho_198))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_1-vocabulary-ApplyThresho_200))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_1#vocabulary]/ApplyThresholdsAndTopK/Top(46)/Flatten/Transcode/0))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_1#vocabulary]/ApplyThresholdsAndTopK/Top(46)/Flatten/Write/0)
[2022-03-24 15:52:39,481] {fn_runner.py:621} INFO - Running (Analyze/VocabularyPrune[compute_and_apply_vocabulary_1#vocabulary]/ApplyThresholdsAndTopK/Top(46)/Flatten/Read)+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_1#vocabulary]/ApplyThresholdsAndTopK/Top(46)/GroupByKey/Write)
[2022-03-24 15:52:39,492] {fn_runner.py:621} INFO - Running ((((((((((Analyze/VocabularyPrune[compute_and_apply_vocabulary_1#vocabulary]/ApplyThresholdsAndTopK/Top(46)/GroupByKey/Read)+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_1-vocabulary-ApplyThresho_208))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_1-vocabulary-ApplyThresho_209))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_1-vocabulary-ApplyThresho_210))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_1-vocabulary-Tota_214))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Extr_231))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_1#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_1#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Writ_241))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Writ_242))+(Analyze/VocabularyOrderAndWrite[compute_and_apply_vocabulary_1#vocabulary]/WriteToText/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:39,529] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Writ_236)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Writ_237))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Writ_239))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Writ_240))+(ref_PCollection_PCollection_130/Write))+(ref_PCollection_PCollection_131/Write)
[2022-03-24 15:52:39,556] {fn_runner.py:621} INFO - Running ((Analyze/VocabularyOrderAndWrite[compute_and_apply_vocabulary_1#vocabulary]/WriteToText/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Writ_244))+(ref_PCollection_PCollection_135/Write)
[2022-03-24 15:52:39,572] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_130/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Writ_245))+(ref_PCollection_PCollection_136/Write)
[2022-03-24 15:52:39,589] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_130/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Writ_246))+(ref_PCollection_PCollection_137/Write)
[2022-03-24 15:52:39,603] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:52:39,704] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:52:39,723] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Crea_248)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Crea_249))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Crea_251))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_1-vocabulary-Wait_252))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_1-vocabulary-temporar_254))+(ref_PCollection_PCollection_142/Write)
[2022-03-24 15:52:39,747] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_242/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Writ_439))+(ref_PCollection_PCollection_248/Write)
[2022-03-24 15:52:39,761] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_242/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Writ_440))+(ref_PCollection_PCollection_249/Write)
[2022-03-24 15:52:39,774] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:52:39,875] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:52:39,894] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Crea_442)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Crea_443))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Crea_445))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_3-vocabulary-Wait_446))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_3-vocabulary-temporar_448))+(ref_PCollection_PCollection_254/Write)
[2022-03-24 15:52:39,917] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex4-Write-WriteImpl-DoOnce-Impulse_700)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex4-Write-WriteImpl-DoOnce-FlatMap-_701))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex4-Write-WriteImpl-DoOnce-Map-deco_703))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex4-Write-WriteImpl-InitializeWrite_704))+(ref_PCollection_PCollection_407/Write))+(ref_PCollection_PCollection_408/Write)
[2022-03-24 15:52:39,937] {fn_runner.py:621} INFO - Running (((((((((((Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_4#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Group/Read)+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_4#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Merge))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary_4#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/ExtractOutputs))+(Analyze/FlattenCache[VocabularyMerge[compute_and_apply_vocabulary_4#vocabulary]]/Flatten/Transcode/0))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_4-vocabu_598))+(ref_AppliedPTransform_Analyze-FlattenCache-VocabularyMerge-compute_and_apply_vocabulary_4-vocabulary_460))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_4#vocabulary]/MergeCountPerToken/Precombine))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_4#vocabulary]/MergeCountPerToken/Group/Write))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex4-Write-WriteImpl-WindowInto-Wind_705))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex4-Write-WriteImpl-WriteBundles_706))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex4-Write-WriteImpl-Pair_707))+(WriteCache/Write[AnalysisIndex0][CacheKeyIndex4]/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:39,972] {fn_runner.py:621} INFO - Running (((((((((((Analyze/VocabularyMerge[compute_and_apply_vocabulary_4#vocabulary]/MergeCountPerToken/Group/Read)+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_4#vocabulary]/MergeCountPerToken/Merge))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary_4#vocabulary]/MergeCountPerToken/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyMerge-compute_and_apply_vocabulary_4-vocabulary-SwapTokensAn_467))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_4-vocabulary-To_471))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_4-vocabulary-KeepOnlyVali_487))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_4#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_4#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_4-vocabulary-ApplyThresho_489))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_4-vocabulary-ApplyThresho_491))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_4#vocabulary]/ApplyThresholdsAndTopK/Top(91)/Flatten/Transcode/0))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_4#vocabulary]/ApplyThresholdsAndTopK/Top(91)/Flatten/Write/0)
[2022-03-24 15:52:40,004] {fn_runner.py:621} INFO - Running ((((Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_4#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_4#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_4#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_4-vocabulary-To_476))+(ref_PCollection_PCollection_267/Write)
[2022-03-24 15:52:40,020] {fn_runner.py:621} INFO - Running ((((((ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_4-vocabulary-To_478)+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_4-vocabulary-To_479))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_4-vocabulary-To_481))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_4-vocabulary-To_482))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_4-vocabulary-To_483))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_4-vocabulary-temporar_485))+(ref_PCollection_PCollection_273/Write)
[2022-03-24 15:52:40,048] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Writ_333)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Writ_334))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Writ_336))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Writ_337))+(ref_PCollection_PCollection_186/Write))+(ref_PCollection_PCollection_187/Write)
[2022-03-24 15:52:40,072] {fn_runner.py:621} INFO - Running ((Analyze/VocabularyOrderAndWrite[compute_and_apply_vocabulary_2#vocabulary]/WriteToText/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Writ_341))+(ref_PCollection_PCollection_191/Write)
[2022-03-24 15:52:40,087] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_186/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Writ_342))+(ref_PCollection_PCollection_192/Write)
[2022-03-24 15:52:40,101] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_186/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Writ_343))+(ref_PCollection_PCollection_193/Write)
[2022-03-24 15:52:40,114] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:52:40,215] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:52:40,234] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Crea_345)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Crea_346))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Crea_348))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_2-vocabulary-Wait_349))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_2-vocabulary-temporar_351))+(ref_PCollection_PCollection_198/Write)
[2022-03-24 15:52:40,262] {fn_runner.py:621} INFO - Running ((((Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_1#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_1#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_1#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_1-vocabulary-Tota_219))+(ref_PCollection_PCollection_120/Write)
[2022-03-24 15:52:40,278] {fn_runner.py:621} INFO - Running ((((((ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_1-vocabulary-Tota_221)+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_1-vocabulary-Tota_222))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_1-vocabulary-Tota_224))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_1-vocabulary-Tota_225))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_1-vocabulary-ToIn_226))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_1-vocabulary-temporar_228))+(ref_PCollection_PCollection_126/Write)
[2022-03-24 15:52:40,305] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Writ_527)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Writ_528))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Writ_530))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Writ_531))+(ref_PCollection_PCollection_298/Write))+(ref_PCollection_PCollection_299/Write)
[2022-03-24 15:52:40,326] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_4-vocabulary-ApplyThresho_493)+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_4-vocabulary-ApplyThresho_494))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_4-vocabulary-ApplyThresho_496))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_4#vocabulary]/ApplyThresholdsAndTopK/Top(91)/Flatten/Transcode/1))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_4#vocabulary]/ApplyThresholdsAndTopK/Top(91)/Flatten/Write/1)
[2022-03-24 15:52:40,344] {fn_runner.py:621} INFO - Running (Analyze/VocabularyPrune[compute_and_apply_vocabulary_4#vocabulary]/ApplyThresholdsAndTopK/Top(91)/Flatten/Read)+(Analyze/VocabularyPrune[compute_and_apply_vocabulary_4#vocabulary]/ApplyThresholdsAndTopK/Top(91)/GroupByKey/Write)
[2022-03-24 15:52:40,355] {fn_runner.py:621} INFO - Running ((((((((((Analyze/VocabularyPrune[compute_and_apply_vocabulary_4#vocabulary]/ApplyThresholdsAndTopK/Top(91)/GroupByKey/Read)+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_4-vocabulary-ApplyThresho_499))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_4-vocabulary-ApplyThresho_500))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary_4-vocabulary-ApplyThresho_501))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_4-vocabulary-Tota_505))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Extr_522))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_4#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_4#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Writ_532))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Writ_533))+(Analyze/VocabularyOrderAndWrite[compute_and_apply_vocabulary_4#vocabulary]/WriteToText/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:40,392] {fn_runner.py:621} INFO - Running ((Analyze/VocabularyOrderAndWrite[compute_and_apply_vocabulary_4#vocabulary]/WriteToText/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Writ_535))+(ref_PCollection_PCollection_303/Write)
[2022-03-24 15:52:40,406] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_298/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Writ_536))+(ref_PCollection_PCollection_304/Write)
[2022-03-24 15:52:40,422] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_298/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Writ_537))+(ref_PCollection_PCollection_305/Write)
[2022-03-24 15:52:40,435] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:52:40,537] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:52:40,555] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Crea_539)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Crea_540))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Crea_542))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary_4-vocabulary-Wait_543))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_4-vocabulary-temporar_545))+(ref_PCollection_PCollection_310/Write)
[2022-03-24 15:52:40,583] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex0-Write-WriteImpl-DoOnce-Impulse_636)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex0-Write-WriteImpl-DoOnce-FlatMap-_637))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex0-Write-WriteImpl-DoOnce-Map-deco_639))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex0-Write-WriteImpl-InitializeWrite_640))+(ref_PCollection_PCollection_363/Write))+(ref_PCollection_PCollection_364/Write)
[2022-03-24 15:52:40,608] {fn_runner.py:621} INFO - Running (((((((((((Analyze/VocabularyAccumulate[compute_and_apply_vocabulary#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Group/Read)+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/Merge))+(Analyze/VocabularyAccumulate[compute_and_apply_vocabulary#vocabulary][AnalysisIndex0]/CountPerToken/CombinePerKey(CountCombineFn)/ExtractOutputs))+(Analyze/FlattenCache[VocabularyMerge[compute_and_apply_vocabulary#vocabulary]]/Flatten/Transcode/0))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary-vocabula_562))+(ref_AppliedPTransform_Analyze-FlattenCache-VocabularyMerge-compute_and_apply_vocabulary-vocabulary-F_72))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary#vocabulary]/MergeCountPerToken/Precombine))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary#vocabulary]/MergeCountPerToken/Group/Write))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex0-Write-WriteImpl-WindowInto-Wind_641))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex0-Write-WriteImpl-WriteBundles_642))+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex0-Write-WriteImpl-Pair_643))+(WriteCache/Write[AnalysisIndex0][CacheKeyIndex0]/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:40,642] {fn_runner.py:621} INFO - Running (((((((((((Analyze/VocabularyMerge[compute_and_apply_vocabulary#vocabulary]/MergeCountPerToken/Group/Read)+(Analyze/VocabularyMerge[compute_and_apply_vocabulary#vocabulary]/MergeCountPerToken/Merge))+(Analyze/VocabularyMerge[compute_and_apply_vocabulary#vocabulary]/MergeCountPerToken/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyMerge-compute_and_apply_vocabulary-vocabulary-SwapTokensAndC_79))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary-vocabulary-Tota_83))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary-vocabulary-KeepOnlyValidS_99))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary-vocabulary-ApplyThreshold_101))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary-vocabulary-ApplyThreshold_103))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary#vocabulary]/ApplyThresholdsAndTopK/Top(12)/Flatten/Transcode/0))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary#vocabulary]/ApplyThresholdsAndTopK/Top(12)/Flatten/Write/0)
[2022-03-24 15:52:40,673] {fn_runner.py:621} INFO - Running ((((Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary-vocabulary-Tota_88))+(ref_PCollection_PCollection_43/Write)
[2022-03-24 15:52:40,697] {fn_runner.py:621} INFO - Running ((((((ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary-vocabulary-Tota_90)+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary-vocabulary-Tota_91))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary-vocabulary-Tota_93))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary-vocabulary-Tota_94))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary-vocabulary-ToIn_95))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary-vocabulary-temporary__97))+(ref_PCollection_PCollection_49/Write)
[2022-03-24 15:52:40,727] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary-vocabulary-ApplyThreshold_105)+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary-vocabulary-ApplyThreshold_106))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary-vocabulary-ApplyThreshold_108))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary#vocabulary]/ApplyThresholdsAndTopK/Top(12)/Flatten/Transcode/1))+(Analyze/VocabularyPrune[compute_and_apply_vocabulary#vocabulary]/ApplyThresholdsAndTopK/Top(12)/Flatten/Write/1)
[2022-03-24 15:52:40,746] {fn_runner.py:621} INFO - Running (Analyze/VocabularyPrune[compute_and_apply_vocabulary#vocabulary]/ApplyThresholdsAndTopK/Top(12)/Flatten/Read)+(Analyze/VocabularyPrune[compute_and_apply_vocabulary#vocabulary]/ApplyThresholdsAndTopK/Top(12)/GroupByKey/Write)
[2022-03-24 15:52:40,757] {fn_runner.py:621} INFO - Running ((((((((((Analyze/VocabularyPrune[compute_and_apply_vocabulary#vocabulary]/ApplyThresholdsAndTopK/Top(12)/GroupByKey/Read)+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary-vocabulary-ApplyThreshold_111))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary-vocabulary-ApplyThreshold_112))+(ref_AppliedPTransform_Analyze-VocabularyPrune-compute_and_apply_vocabulary-vocabulary-ApplyThreshold_113))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary-vocabulary-TotalV_117))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-Extrac_134))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-WriteT_144))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-WriteT_145))+(Analyze/VocabularyOrderAndWrite[compute_and_apply_vocabulary#vocabulary]/WriteToText/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:40,792] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-WriteT_139)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-WriteT_140))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-WriteT_142))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-WriteT_143))+(ref_PCollection_PCollection_74/Write))+(ref_PCollection_PCollection_75/Write)
[2022-03-24 15:52:40,812] {fn_runner.py:621} INFO - Running ((Analyze/VocabularyOrderAndWrite[compute_and_apply_vocabulary#vocabulary]/WriteToText/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-WriteT_147))+(ref_PCollection_PCollection_79/Write)
[2022-03-24 15:52:40,827] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_74/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-WriteT_148))+(ref_PCollection_PCollection_80/Write)
[2022-03-24 15:52:40,842] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_74/Read)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-WriteT_149))+(ref_PCollection_PCollection_81/Write)
[2022-03-24 15:52:40,854] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:52:40,955] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:52:40,974] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-Create_151)+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-Create_152))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-Create_154))+(ref_AppliedPTransform_Analyze-VocabularyOrderAndWrite-compute_and_apply_vocabulary-vocabulary-WaitFo_155))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary-vocabulary-temporary__157))+(ref_PCollection_PCollection_86/Write)
[2022-03-24 15:52:41,002] {fn_runner.py:621} INFO - Running ((((Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_4#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_4#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary_4#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_4-vocabulary-Tota_510))+(ref_PCollection_PCollection_288/Write)
[2022-03-24 15:52:41,017] {fn_runner.py:621} INFO - Running ((((((ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_4-vocabulary-Tota_512)+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_4-vocabulary-Tota_513))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_4-vocabulary-Tota_515))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_4-vocabulary-Tota_516))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary_4-vocabulary-ToIn_517))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_4-vocabulary-temporar_519))+(ref_PCollection_PCollection_294/Write)
[2022-03-24 15:52:41,049] {fn_runner.py:621} INFO - Running ((((Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_1#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_1#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(Analyze/VocabularyCountUnfiltered[compute_and_apply_vocabulary_1#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_1-vocabulary-To_185))+(ref_PCollection_PCollection_99/Write)
[2022-03-24 15:52:41,068] {fn_runner.py:621} INFO - Running ((((((ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_1-vocabulary-To_187)+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_1-vocabulary-To_188))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_1-vocabulary-To_190))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_1-vocabulary-To_191))+(ref_AppliedPTransform_Analyze-VocabularyCountUnfiltered-compute_and_apply_vocabulary_1-vocabulary-To_192))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary_1-vocabulary-temporar_194))+(ref_PCollection_PCollection_105/Write)
[2022-03-24 15:52:41,099] {fn_runner.py:621} INFO - Running ((((Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(Analyze/VocabularyCountFiltered[compute_and_apply_vocabulary#vocabulary]/TotalVocabSize/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary-vocabulary-TotalV_122))+(ref_PCollection_PCollection_64/Write)
[2022-03-24 15:52:41,117] {fn_runner.py:621} INFO - Running ((((((ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary-vocabulary-TotalV_124)+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary-vocabulary-TotalV_125))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary-vocabulary-TotalV_127))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary-vocabulary-TotalV_128))+(ref_AppliedPTransform_Analyze-VocabularyCountFiltered-compute_and_apply_vocabulary-vocabulary-ToInt6_129))+(ref_AppliedPTransform_Analyze-CreateTensorBinding-compute_and_apply_vocabulary-vocabulary-temporary__131))+(ref_PCollection_PCollection_70/Write)
[2022-03-24 15:52:41,148] {fn_runner.py:621} INFO - Running ((((((((((((((((((((ref_AppliedPTransform_Analyze-CreateSavedModel-tf_v2_only-CreateSole-Impulse_548)+(ref_AppliedPTransform_Analyze-CreateSavedModel-tf_v2_only-CreateSole-FlatMap-lambda-at-core-py-3228-_549))+(ref_AppliedPTransform_Analyze-CreateSavedModel-tf_v2_only-CreateSole-Map-decode-_551))+(ref_AppliedPTransform_Analyze-CreateSavedModel-tf_v2_only-ReplaceWithConstants_552))+(ref_AppliedPTransform_Analyze-CreateSavedModel-tf_v2_only-CreateSavedModel_553))+(ref_AppliedPTransform_Analyze-ComputeDeferredMetadata-compat_v1-False-_606))+(ref_AppliedPTransform_Analyze-MakeCheapBarrier_607))+(ref_AppliedPTransform_WriteTransformFn-WriteTransformFnToTemp_624))+(ref_PCollection_PCollection_315/Write))+(ref_AppliedPTransform_WriteTransformFn-WriteMetadataToTemp-WriteMetadata_623))+(ref_AppliedPTransform_Transform-TransformIndex0-GetDeferredSchema_875))+(ref_AppliedPTransform_Transform-TransformIndex1-GetDeferredSchema_906))+(ref_PCollection_PCollection_346/Write))+(ref_PCollection_PCollection_355/Write))+(ref_PCollection_PCollection_356/Write))+(ref_AppliedPTransform_Transform-TransformIndex0-MakeTensorToArrowConverter_877))+(ref_PCollection_PCollection_510/Write))+(ref_PCollection_PCollection_512/Write))+(ref_AppliedPTransform_Transform-TransformIndex1-MakeTensorToArrowConverter_908))+(ref_PCollection_PCollection_527/Write))+(ref_PCollection_PCollection_529/Write)
[2022-03-24 15:52:41,220] {logging_mixin.py:109} INFO - Columns: dict_keys(['Company', 'Company public response', 'Company response to consumer', 'Complaint ID', 'Consumer complaint narrative', 'Consumer consent provided?', 'Consumer disputed?', 'Date received', 'Date sent to company', 'Issue', 'Product', 'State', 'Sub-issue', 'Sub-product', 'Submitted via', 'Tags', 'Timely response?', 'ZIP code'])
[2022-03-24 15:52:41,220] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:52:41,220] {logging_mixin.py:109} INFO - Column: Tensor("inputs_16_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:52:41,229] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:52:41,231] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:52:41,239] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:52:41,239] {logging_mixin.py:109} INFO - Column: Tensor("inputs_4_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:52:41,247] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:52:41,249] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_1:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:52:41,257] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:52:41,257] {logging_mixin.py:109} INFO - Column: Tensor("inputs_15_copy:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:52:41,265] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:52:41,267] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_2:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:52:41,470] {builder_impl.py:784} INFO - Assets written to: /opt/***/census_consumer_complaint_data/census_consumer_complaint/artifact/Transform/transform_graph/10/.temp_path/tftransform_tmp/b6a59bbdda6b47b38f98498a2e6dc4b0/assets
[2022-03-24 15:52:41,534] {logging_mixin.py:109} INFO - Columns: dict_keys(['Company', 'Company public response', 'Company response to consumer', 'Complaint ID', 'Consumer complaint narrative', 'Consumer consent provided?', 'Consumer disputed?', 'Date received', 'Date sent to company', 'Issue', 'Product', 'State', 'Sub-issue', 'Sub-product', 'Submitted via', 'Tags', 'Timely response?', 'ZIP code'])
[2022-03-24 15:52:41,534] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:52:41,534] {logging_mixin.py:109} INFO - Column: Tensor("PlaceholderWithDefault_16:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:52:41,541] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:52:41,544] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:52:41,552] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:52:41,552] {logging_mixin.py:109} INFO - Column: Tensor("PlaceholderWithDefault_4:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:52:41,559] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:52:41,561] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_1:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:52:41,569] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.ops.Tensor'>
[2022-03-24 15:52:41,569] {logging_mixin.py:109} INFO - Column: Tensor("PlaceholderWithDefault_15:0", shape=(None, 1), dtype=string) has been updated: False
[2022-03-24 15:52:41,576] {logging_mixin.py:109} INFO - <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>
[2022-03-24 15:52:41,579] {logging_mixin.py:109} INFO - Column: Tensor("SparseToDense_2:0", shape=(None, 1), dtype=string) has been updated: True
[2022-03-24 15:52:41,659] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex1-RawRecordBeamSource-ReadRawRecords-ReadFrom_891)+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex1-RawRecordBeamSource-ReadRawRecords-ReadFrom_892))+(TFXIOReadAndDecode[TransformIndex1]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/PairWithRestriction))+(TFXIOReadAndDecode[TransformIndex1]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/SplitAndSizeRestriction))+(ref_PCollection_PCollection_520_split/Write)
[2022-03-24 15:52:41,695] {fn_runner.py:621} INFO - Running ((((((((((((((((((ref_PCollection_PCollection_520_split/Read)+(TFXIOReadAndDecode[TransformIndex1]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process))+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex1-RawRecordBeamSource-ReadRawRecords-FlattenP_895))+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex1-RawRecordBeamSource-CollectRawRecordTelemet_897))+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex1-RawRecordToRecordBatch-RawRecordToRecordBat_901))+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex1-RawRecordToRecordBatch-RawRecordToRecordBat_902))+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex1-RawRecordToRecordBatch-CollectRecordBatchTe_904))+(ref_AppliedPTransform_Transform-TransformIndex1-Transform_907))+(ref_AppliedPTransform_Transform-TransformIndex1-ConvertToRecordBatch_909))+(ref_AppliedPTransform_Transform-TransformIndex1-MakeCheapBarrier_910))+(ref_AppliedPTransform_ExtractRecordBatches-TransformIndex1-Keys_920))+(ref_AppliedPTransform_EncodeAndSerialize-TransformIndex1-_1101))+(ref_PCollection_PCollection_531/Write))+(FlattenTransformedDatasets/Write/1))+(ref_AppliedPTransform_Materialize-TransformIndex1-Values-Values_1104))+(ref_AppliedPTransform_Materialize-TransformIndex1-Write-Write-WriteImpl-WindowInto-WindowIntoFn-_1114))+(ref_AppliedPTransform_Materialize-TransformIndex1-Write-Write-WriteImpl-WriteBundles_1115))+(ref_AppliedPTransform_Materialize-TransformIndex1-Write-Write-WriteImpl-Pair_1116))+(Materialize[TransformIndex1]/Write/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:52:42,138] {saved_transform_io.py:166} INFO - tensorflow_text is not available.
[2022-03-24 15:52:42,139] {saved_transform_io.py:166} INFO - tensorflow_decision_forests is not available.
[2022-03-24 15:52:42,139] {saved_transform_io.py:166} INFO - struct2tensor is not available.
[2022-03-24 15:55:40,431] {fn_runner.py:621} INFO - Running ((Materialize[TransformIndex1]/Write/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_Materialize-TransformIndex1-Write-Write-WriteImpl-Extract_1118))+(ref_PCollection_PCollection_659/Write)
[2022-03-24 15:55:40,450] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_653/Read)+(ref_AppliedPTransform_Materialize-TransformIndex1-Write-Write-WriteImpl-PreFinalize_1119))+(ref_PCollection_PCollection_660/Write)
[2022-03-24 15:55:40,468] {fn_runner.py:621} INFO - Running ((((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Group/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Merge))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_811))+(ref_PCollection_PCollection_473/Write)
[2022-03-24 15:55:40,491] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteSchema-Write-WriteI_1054)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteSchema-Write-WriteI_1055))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteSchema-Write-WriteI_1057))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteSchema-Write-WriteI_1058))+(ref_PCollection_PCollection_617/Write))+(ref_PCollection_PCollection_618/Write)
[2022-03-24 15:55:40,512] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-CreateSchema-Impulse_1046)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-CreateSchema-FlatMap-lam_1047))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-CreateSchema-Map-decode-_1049))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteSchema-Write-WriteI_1059))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteSchema-Write-WriteI_1060))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/WriteSchema/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:55:40,537] {fn_runner.py:621} INFO - Running ((GenerateAndValidateStats[FlattenedTransformedDatasets]/WriteSchema/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteSchema-Write-WriteI_1062))+(ref_PCollection_PCollection_622/Write)
[2022-03-24 15:55:40,553] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_617/Read)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteSchema-Write-WriteI_1063))+(ref_PCollection_PCollection_623/Write)
[2022-03-24 15:55:40,567] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_617/Read)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteSchema-Write-WriteI_1064)
[2022-03-24 15:55:40,583] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:55:40,684] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:55:40,691] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteValidation-Write-Wr_1070)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteValidation-Write-Wr_1071))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteValidation-Write-Wr_1073))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteValidation-Write-Wr_1074))+(ref_PCollection_PCollection_628/Write))+(ref_PCollection_PCollection_629/Write)
[2022-03-24 15:55:40,712] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_WriteTransformFn-CreateSole-Impulse_626)+(ref_AppliedPTransform_WriteTransformFn-CreateSole-FlatMap-lambda-at-core-py-3228-_627))+(ref_AppliedPTransform_WriteTransformFn-CreateSole-Map-decode-_629))+(ref_AppliedPTransform_WriteTransformFn-PublishMetadataAndTransformFn_630))+(ref_PCollection_PCollection_360/Write)
[2022-03-24 15:55:40,735] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex0-RawRecordBeamSource-ReadRawRecords-ReadFrom_860)+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex0-RawRecordBeamSource-ReadRawRecords-ReadFrom_861))+(TFXIOReadAndDecode[TransformIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/PairWithRestriction))+(TFXIOReadAndDecode[TransformIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/SplitAndSizeRestriction))+(ref_PCollection_PCollection_503_split/Write)
[2022-03-24 15:55:40,765] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_Materialize-TransformIndex0-Write-Write-WriteImpl-DoOnce-Impulse_1089)+(ref_AppliedPTransform_Materialize-TransformIndex0-Write-Write-WriteImpl-DoOnce-FlatMap-lambda-at-cor_1090))+(ref_AppliedPTransform_Materialize-TransformIndex0-Write-Write-WriteImpl-DoOnce-Map-decode-_1092))+(ref_AppliedPTransform_Materialize-TransformIndex0-Write-Write-WriteImpl-InitializeWrite_1093))+(ref_PCollection_PCollection_640/Write))+(ref_PCollection_PCollection_641/Write)
[2022-03-24 15:55:40,787] {fn_runner.py:621} INFO - Running ((((((((((((((((((ref_PCollection_PCollection_503_split/Read)+(TFXIOReadAndDecode[TransformIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process))+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex0-RawRecordBeamSource-ReadRawRecords-FlattenP_864))+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex0-RawRecordBeamSource-CollectRawRecordTelemet_866))+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex0-RawRecordToRecordBatch-RawRecordToRecordBat_870))+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex0-RawRecordToRecordBatch-RawRecordToRecordBat_871))+(ref_AppliedPTransform_TFXIOReadAndDecode-TransformIndex0-RawRecordToRecordBatch-CollectRecordBatchTe_873))+(ref_AppliedPTransform_Transform-TransformIndex0-Transform_876))+(ref_AppliedPTransform_Transform-TransformIndex0-ConvertToRecordBatch_878))+(ref_AppliedPTransform_Transform-TransformIndex0-MakeCheapBarrier_879))+(ref_AppliedPTransform_ExtractRecordBatches-TransformIndex0-Keys_918))+(ref_AppliedPTransform_EncodeAndSerialize-TransformIndex0-_1081))+(ref_PCollection_PCollection_514/Write))+(FlattenTransformedDatasets/Write/0))+(ref_AppliedPTransform_Materialize-TransformIndex0-Values-Values_1084))+(ref_AppliedPTransform_Materialize-TransformIndex0-Write-Write-WriteImpl-WindowInto-WindowIntoFn-_1094))+(ref_AppliedPTransform_Materialize-TransformIndex0-Write-Write-WriteImpl-WriteBundles_1095))+(ref_AppliedPTransform_Materialize-TransformIndex0-Write-Write-WriteImpl-Pair_1096))+(Materialize[TransformIndex0]/Write/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:55:41,191] {saved_transform_io.py:166} INFO - tensorflow_text is not available.
[2022-03-24 15:55:41,191] {saved_transform_io.py:166} INFO - tensorflow_decision_forests is not available.
[2022-03-24 15:55:41,191] {saved_transform_io.py:166} INFO - struct2tensor is not available.
[2022-03-24 15:57:11,106] {fn_runner.py:621} INFO - Running (((((((((((((((((((((FlattenTransformedDatasets/Read)+(ref_AppliedPTransform_WaitForTransformWrite_922))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-FilterInternalColumn_924))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_928))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_943))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_930))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackTotalBytes/SumTotalBytes/CombinePerKey/Precombine))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackTotalBytes/SumTotalBytes/CombinePerKey/Group/Write))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_946))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_972))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_999))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_948))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/RemoveDuplicates/Group/Precombine))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/RemoveDuplicates/Group/Group/Write))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_974))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/CombineCountsAndWeights/CombinePerKey(sum)/Precombine))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/CombineCountsAndWeights/CombinePerKey(sum)/Group/Write))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/Flatten/Transcode/0))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1000))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PreCombineFn)/Precombine))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PreCombineFn)/Group/Write))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/Flatten/Write/0)
[2022-03-24 15:57:21,149] {fn_runner.py:621} INFO - Running (((((((((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/CombineCountsAndWeights/CombinePerKey(sum)/Group/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/CombineCountsAndWeights/CombinePerKey(sum)/Merge))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/CombineCountsAndWeights/CombinePerKey(sum)/ExtractOutputs))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_979))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Unweighted_TopK/CombinePerKey(TopCombineFn)/Precombine))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_988))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Unweighted_TopK/CombinePerKey(TopCombineFn)/Group/Write))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_990))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Precombine))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Group/Write)
[2022-03-24 15:57:23,680] {fn_runner.py:621} INFO - Running (((((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Unweighted_TopK/CombinePerKey(TopCombineFn)/Group/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Unweighted_TopK/CombinePerKey(TopCombineFn)/Merge))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Unweighted_TopK/CombinePerKey(TopCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_985))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_986))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesFeatureStatsProtos/Write/0)
[2022-03-24 15:57:23,724] {fn_runner.py:621} INFO - Running ((((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Group/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Merge))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_995))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesFeatureStatsProtos/Write/1)
[2022-03-24 15:57:23,753] {fn_runner.py:621} INFO - Running ((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesFeatureStatsProtos/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Transcode/0))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Write/0)
[2022-03-24 15:57:23,784] {fn_runner.py:621} INFO - Running ((((((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PreCombineFn)/Group/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PreCombineFn)/Merge))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PreCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1005))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1006))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/Flatten/Transcode/1))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/Flatten/Write/1)
[2022-03-24 15:57:23,827] {fn_runner.py:621} INFO - Running ((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/Flatten/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PostCombineFn)/Precombine))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PostCombineFn)/Group/Write)
[2022-03-24 15:57:23,871] {fn_runner.py:621} INFO - Running ((((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PostCombineFn)/Group/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PostCombineFn)/Merge))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/RunCombinerStatsGenerators/CombinePerKey(PostCombineFn)/ExtractOutputs))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Transcode/1))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Write/1)
[2022-03-24 15:57:23,928] {fn_runner.py:621} INFO - Running ((((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Read)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1013))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1016))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Precombine))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Group/Write)
[2022-03-24 15:57:23,993] {fn_runner.py:621} INFO - Running ((((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Group/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Merge))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1021))+(ref_PCollection_PCollection_596/Write)
[2022-03-24 15:57:24,056] {fn_runner.py:621} INFO - Running (((((((((((ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1023)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1024))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1026))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1027))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_1028))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteStats-WriteStats-Wr_1039))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-ValidateStatistics_1065))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteStats-WriteStats-Wr_1040))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/WriteStats/WriteStats/Write/WriteImpl/GroupByKey/Write))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteValidation-Write-Wr_1075))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteValidation-Write-Wr_1076))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/WriteValidation/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:57:24,139] {fn_runner.py:621} INFO - Running ((GenerateAndValidateStats[FlattenedTransformedDatasets]/WriteValidation/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteValidation-Write-Wr_1078))+(ref_PCollection_PCollection_633/Write)
[2022-03-24 15:57:24,193] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_628/Read)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteValidation-Write-Wr_1079))+(ref_PCollection_PCollection_634/Write)
[2022-03-24 15:57:24,223] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_2-vocabu_583)+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_2-vocabu_584))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_2-vocabu_586))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_2-vocabu_587)
[2022-03-24 15:57:24,270] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_628/Read)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteValidation-Write-Wr_1080)
[2022-03-24 15:57:24,284] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:24,385] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:24,432] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_IncrementPipelineMetrics-CreateSole-Impulse_10)+(ref_AppliedPTransform_IncrementPipelineMetrics-CreateSole-FlatMap-lambda-at-core-py-3228-_11))+(ref_AppliedPTransform_IncrementPipelineMetrics-CreateSole-Map-decode-_13))+(ref_AppliedPTransform_IncrementPipelineMetrics-Count_14)
[2022-03-24 15:57:24,454] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Analyze-CreateSavedModelForAnalyzerInputs-Phase0-tf_v2_only-Count-CreateSole-I_51)+(ref_AppliedPTransform_Analyze-CreateSavedModelForAnalyzerInputs-Phase0-tf_v2_only-Count-CreateSole-F_52))+(ref_AppliedPTransform_Analyze-CreateSavedModelForAnalyzerInputs-Phase0-tf_v2_only-Count-CreateSole-M_54))+(ref_AppliedPTransform_Analyze-CreateSavedModelForAnalyzerInputs-Phase0-tf_v2_only-Count-Count_55)
[2022-03-24 15:57:24,476] {fn_runner.py:621} INFO - Running ((WriteCache/Write[AnalysisIndex0][CacheKeyIndex0]/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex0-Write-WriteImpl-Extract_645))+(ref_PCollection_PCollection_369/Write)
[2022-03-24 15:57:24,491] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_363/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex0-Write-WriteImpl-PreFinalize_646))+(ref_PCollection_PCollection_370/Write)
[2022-03-24 15:57:24,506] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_363/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex0-Write-WriteImpl-FinalizeWrite_647)
[2022-03-24 15:57:24,520] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:24,621] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:24,642] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_653/Read)+(ref_AppliedPTransform_Materialize-TransformIndex1-Write-Write-WriteImpl-FinalizeWrite_1120)
[2022-03-24 15:57:24,655] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:24,756] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:24,777] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_WriteMetadata-Create-Impulse_616)+(ref_AppliedPTransform_WriteMetadata-Create-FlatMap-lambda-at-core-py-3228-_617))+(ref_AppliedPTransform_WriteMetadata-Create-Map-decode-_619))+(ref_AppliedPTransform_WriteMetadata-WriteMetadata_620)
[2022-03-24 15:57:24,803] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteStats-WriteStats-Wr_1034)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteStats-WriteStats-Wr_1035))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteStats-WriteStats-Wr_1037))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteStats-WriteStats-Wr_1038))+(ref_PCollection_PCollection_604/Write))+(ref_PCollection_PCollection_605/Write)
[2022-03-24 15:57:24,839] {fn_runner.py:621} INFO - Running ((GenerateAndValidateStats[FlattenedTransformedDatasets]/WriteStats/WriteStats/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteStats-WriteStats-Wr_1042))+(ref_PCollection_PCollection_609/Write)
[2022-03-24 15:57:24,899] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_604/Read)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteStats-WriteStats-Wr_1043))+(ref_PCollection_PCollection_610/Write)
[2022-03-24 15:57:24,957] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_604/Read)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-WriteStats-WriteStats-Wr_1044)
[2022-03-24 15:57:24,971] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:25,072] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:25,120] {fn_runner.py:621} INFO - Running ((Materialize[TransformIndex0]/Write/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_Materialize-TransformIndex0-Write-Write-WriteImpl-Extract_1098))+(ref_PCollection_PCollection_646/Write)
[2022-03-24 15:57:25,138] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Analyze-InstrumentAPI-CreateSoleAPIUse-Impulse_37)+(ref_AppliedPTransform_Analyze-InstrumentAPI-CreateSoleAPIUse-FlatMap-lambda-at-core-py-3228-_38))+(ref_AppliedPTransform_Analyze-InstrumentAPI-CreateSoleAPIUse-Map-decode-_40))+(ref_AppliedPTransform_Analyze-InstrumentAPI-CountAPIUse_41)
[2022-03-24 15:57:25,168] {fn_runner.py:621} INFO - Running ((WriteCache/Write[AnalysisIndex0][CacheKeyIndex1]/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex1-Write-WriteImpl-Extract_661))+(ref_PCollection_PCollection_380/Write)
[2022-03-24 15:57:25,182] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_374/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex1-Write-WriteImpl-PreFinalize_662))+(ref_PCollection_PCollection_381/Write)
[2022-03-24 15:57:25,198] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_374/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex1-Write-WriteImpl-FinalizeWrite_663)
[2022-03-24 15:57:25,212] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:25,313] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:25,333] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_640/Read)+(ref_AppliedPTransform_Materialize-TransformIndex0-Write-Write-WriteImpl-PreFinalize_1099))+(ref_PCollection_PCollection_647/Write)
[2022-03-24 15:57:25,348] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_1-vocabu_574)+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_1-vocabu_575))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_1-vocabu_577))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_1-vocabu_578)
[2022-03-24 15:57:25,369] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_3-vocabu_592)+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_3-vocabu_593))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_3-vocabu_595))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_3-vocabu_596)
[2022-03-24 15:57:25,389] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Analyze-PrepareToClearSharedKeepAlives-Impulse_609)+(ref_AppliedPTransform_Analyze-PrepareToClearSharedKeepAlives-FlatMap-lambda-at-core-py-3228-_610))+(ref_AppliedPTransform_Analyze-PrepareToClearSharedKeepAlives-Map-decode-_612))+(ref_AppliedPTransform_Analyze-WaitAndClearSharedKeepAlives_613)
[2022-03-24 15:57:25,409] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_4-vocabu_601)+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_4-vocabu_602))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_4-vocabu_604))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary_4-vocabu_605)
[2022-03-24 15:57:25,432] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_640/Read)+(ref_AppliedPTransform_Materialize-TransformIndex0-Write-Write-WriteImpl-FinalizeWrite_1100)
[2022-03-24 15:57:25,445] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:25,546] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:25,570] {fn_runner.py:621} INFO - Running ((WriteCache/Write[AnalysisIndex0][CacheKeyIndex3]/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex3-Write-WriteImpl-Extract_693))+(ref_PCollection_PCollection_402/Write)
[2022-03-24 15:57:25,600] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_396/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex3-Write-WriteImpl-PreFinalize_694))+(ref_PCollection_PCollection_403/Write)
[2022-03-24 15:57:25,617] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_396/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex3-Write-WriteImpl-FinalizeWrite_695)
[2022-03-24 15:57:25,633] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:25,734] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:25,752] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteStats-WriteStats-Write-WriteImpl-D_824)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteStats-WriteStats-Write-WriteImpl-D_825))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteStats-WriteStats-Write-WriteImpl-D_827))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteStats-WriteStats-Write-WriteImpl-I_828))+(ref_PCollection_PCollection_481/Write))+(ref_PCollection_PCollection_482/Write)
[2022-03-24 15:57:25,774] {fn_runner.py:621} INFO - Running (((((((ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_813)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_814))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_816))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_817))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-G_818))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteStats-WriteStats-Write-WriteImpl-M_829))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteStats-WriteStats-Write-WriteImpl-W_830))+(GenerateStats[FlattenedAnalysisDataset]/WriteStats/WriteStats/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:57:25,817] {fn_runner.py:621} INFO - Running ((GenerateStats[FlattenedAnalysisDataset]/WriteStats/WriteStats/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteStats-WriteStats-Write-WriteImpl-W_832))+(ref_PCollection_PCollection_486/Write)
[2022-03-24 15:57:25,835] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary-vocabula_565)+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary-vocabula_566))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary-vocabula_568))+(ref_AppliedPTransform_Analyze-EncodeCache-VocabularyAccumulate-compute_and_apply_vocabulary-vocabula_569)
[2022-03-24 15:57:25,856] {fn_runner.py:621} INFO - Running ((WriteCache/Write[AnalysisIndex0][CacheKeyIndex2]/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex2-Write-WriteImpl-Extract_677))+(ref_PCollection_PCollection_391/Write)
[2022-03-24 15:57:25,870] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_385/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex2-Write-WriteImpl-PreFinalize_678))+(ref_PCollection_PCollection_392/Write)
[2022-03-24 15:57:25,890] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_385/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex2-Write-WriteImpl-FinalizeWrite_679)
[2022-03-24 15:57:25,903] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:26,004] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:26,026] {fn_runner.py:621} INFO - Running ((((((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/RemoveDuplicates/Group/Group/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/RemoveDuplicates/Group/Merge))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/RemoveDuplicates/Group/ExtractOutputs))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_954))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_957))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write)
[2022-03-24 15:57:26,057] {fn_runner.py:621} INFO - Running ((((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_962))+(ref_PCollection_PCollection_560/Write)
[2022-03-24 15:57:26,086] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_964)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_965))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_967))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_968))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_969)
[2022-03-24 15:57:26,116] {fn_runner.py:621} INFO - Running ((ref_AppliedPTransform_OptimizeRun-WorkaroundForBug170304777-Impulse_4)+(ref_AppliedPTransform_OptimizeRun-WorkaroundForBug170304777-FlatMap-lambda-at-core-py-3228-_5))+(ref_AppliedPTransform_OptimizeRun-WorkaroundForBug170304777-Map-decode-_7)
[2022-03-24 15:57:26,135] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-CreateSchema-Impulse_836)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-CreateSchema-FlatMap-lambda-at-core-py-_837))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-CreateSchema-Map-decode-_839))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteSchema-Write-WriteImpl-Map-lambda-_849))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteSchema-Write-WriteImpl-WindowInto-_850))+(GenerateStats[FlattenedAnalysisDataset]/WriteSchema/Write/WriteImpl/GroupByKey/Write)
[2022-03-24 15:57:26,166] {fn_runner.py:621} INFO - Running (((((ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteSchema-Write-WriteImpl-DoOnce-Impu_844)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteSchema-Write-WriteImpl-DoOnce-Flat_845))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteSchema-Write-WriteImpl-DoOnce-Map-_847))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteSchema-Write-WriteImpl-InitializeW_848))+(ref_PCollection_PCollection_494/Write))+(ref_PCollection_PCollection_495/Write)
[2022-03-24 15:57:26,191] {fn_runner.py:621} INFO - Running ((GenerateStats[FlattenedAnalysisDataset]/WriteSchema/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteSchema-Write-WriteImpl-WriteBundle_852))+(ref_PCollection_PCollection_499/Write)
[2022-03-24 15:57:26,213] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_481/Read)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteStats-WriteStats-Write-WriteImpl-P_833))+(ref_PCollection_PCollection_487/Write)
[2022-03-24 15:57:26,231] {fn_runner.py:621} INFO - Running ((WriteCache/Write[AnalysisIndex0][CacheKeyIndex4]/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex4-Write-WriteImpl-Extract_709))+(ref_PCollection_PCollection_413/Write)
[2022-03-24 15:57:26,247] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_407/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex4-Write-WriteImpl-PreFinalize_710))+(ref_PCollection_PCollection_414/Write)
[2022-03-24 15:57:26,263] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_407/Read)+(ref_AppliedPTransform_WriteCache-Write-AnalysisIndex0-CacheKeyIndex4-Write-WriteImpl-FinalizeWrite_711)
[2022-03-24 15:57:26,279] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:26,380] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:26,402] {fn_runner.py:621} INFO - Running ((((GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackTotalBytes/SumTotalBytes/CombinePerKey/Group/Read)+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackTotalBytes/SumTotalBytes/CombinePerKey/Merge))+(GenerateAndValidateStats[FlattenedTransformedDatasets]/GenerateStatistics/RunStatsGenerators/TrackTotalBytes/SumTotalBytes/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_935))+(ref_PCollection_PCollection_545/Write)
[2022-03-24 15:57:26,428] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_937)+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_938))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_940))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_941))+(ref_AppliedPTransform_GenerateAndValidateStats-FlattenedTransformedDatasets-GenerateStatistics-RunSt_942)
[2022-03-24 15:57:26,456] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Analyze-CreateSavedModel-tf_v2_only-Count-CreateSole-Impulse_556)+(ref_AppliedPTransform_Analyze-CreateSavedModel-tf_v2_only-Count-CreateSole-FlatMap-lambda-at-core-py_557))+(ref_AppliedPTransform_Analyze-CreateSavedModel-tf_v2_only-Count-CreateSole-Map-decode-_559))+(ref_AppliedPTransform_Analyze-CreateSavedModel-tf_v2_only-Count-Count_560)
[2022-03-24 15:57:26,477] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_481/Read)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteStats-WriteStats-Write-WriteImpl-F_834)
[2022-03-24 15:57:26,490] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:26,591] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:26,609] {fn_runner.py:621} INFO - Running ((ref_PCollection_PCollection_494/Read)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteSchema-Write-WriteImpl-PreFinalize_853))+(ref_PCollection_PCollection_500/Write)
[2022-03-24 15:57:26,624] {fn_runner.py:621} INFO - Running (ref_PCollection_PCollection_494/Read)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-WriteSchema-Write-WriteImpl-FinalizeWri_854)
[2022-03-24 15:57:26,643] {filebasedsink.py:303} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2022-03-24 15:57:26,744] {filebasedsink.py:348} INFO - Renamed 1 shards in 0.10 seconds.
[2022-03-24 15:57:26,763] {fn_runner.py:621} INFO - Running ((((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackTotalBytes/SumTotalBytes/CombinePerKey/Group/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackTotalBytes/SumTotalBytes/CombinePerKey/Merge))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackTotalBytes/SumTotalBytes/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_725))+(ref_PCollection_PCollection_422/Write)
[2022-03-24 15:57:26,779] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_727)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_728))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_730))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_731))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_732)
[2022-03-24 15:57:26,804] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Transform-TransformIndex1-PrepareToClearSharedKeepAlives-Impulse_912)+(ref_AppliedPTransform_Transform-TransformIndex1-PrepareToClearSharedKeepAlives-FlatMap-lambda-at-cor_913))+(ref_AppliedPTransform_Transform-TransformIndex1-PrepareToClearSharedKeepAlives-Map-decode-_915))+(ref_AppliedPTransform_Transform-TransformIndex1-WaitAndClearSharedKeepAlives_916)
[2022-03-24 15:57:26,825] {fn_runner.py:621} INFO - Running ((((((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/RemoveDuplicates/Group/Group/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/RemoveDuplicates/Group/Merge))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/RemoveDuplicates/Group/ExtractOutputs))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_744))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_747))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write)
[2022-03-24 15:57:26,845] {fn_runner.py:621} INFO - Running ((((GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(GenerateStats[FlattenedAnalysisDataset]/GenerateStatistics/RunStatsGenerators/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_752))+(ref_PCollection_PCollection_437/Write)
[2022-03-24 15:57:26,861] {fn_runner.py:621} INFO - Running ((((ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_754)+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_755))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_757))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_758))+(ref_AppliedPTransform_GenerateStats-FlattenedAnalysisDataset-GenerateStatistics-RunStatsGenerators-T_759)
[2022-03-24 15:57:26,886] {fn_runner.py:621} INFO - Running (((ref_AppliedPTransform_Transform-TransformIndex0-PrepareToClearSharedKeepAlives-Impulse_881)+(ref_AppliedPTransform_Transform-TransformIndex0-PrepareToClearSharedKeepAlives-FlatMap-lambda-at-cor_882))+(ref_AppliedPTransform_Transform-TransformIndex0-PrepareToClearSharedKeepAlives-Map-decode-_884))+(ref_AppliedPTransform_Transform-TransformIndex0-WaitAndClearSharedKeepAlives_885)
[2022-03-24 15:57:26,948] {python.py:175} INFO - Done. Returned value was: None
[2022-03-24 15:57:26,955] {taskinstance.py:1282} INFO - Marking task as SUCCESS. dag_id=census_consumer_complaint, task_id=Transform, execution_date=20220324T154229, start_date=20220324T155056, end_date=20220324T155726
[2022-03-24 15:57:27,074] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-24 15:57:27,097] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
